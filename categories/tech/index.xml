<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>tech - Category - 152334H</title><link>https://152334H.github.io/categories/tech/</link><description>tech - Category - 152334H</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 11 Feb 2023 08:13:30 +0800</lastBuildDate><atom:link href="https://152334H.github.io/categories/tech/" rel="self" type="application/rss+xml"/><item><title>Blog Refurbishment</title><link>https://152334H.github.io/blog/blog-refurbishment/</link><pubDate>Sat, 13 Aug 2022 05:30:32 +0100</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/blog-refurbishment/</guid><description>Under new management</description></item><item><title>Why can't TorToiSe be fine-tuned?</title><link>https://152334H.github.io/blog/tortoise-fine-tuning/</link><pubDate>Sat, 11 Feb 2023 08:13:30 +0800</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/tortoise-fine-tuning/</guid><description><![CDATA[<p><a href="http://nonint.com/static/tortoise_v2_examples.html" target="_blank" rel="noopener noreffer ">TorToiSe üê¢</a> is an open-source Text-To-Speech (TTS) neural network that <abbr tabindex="0" title="It is also notable for its alleged similiarity to 11labs's TTS stack." style="color:#bbb;text-decoration-style: dotted;text-decoration-line:underline">creates fairly authentic &amp; realistic voices</abbr>. Checkpoints for local inference have been available since <a href="https://huggingface.co/jbetker/tortoise-tts-v2/tree/main/.models" target="_blank" rel="noopener noreffer ">April last year</a>, but its users are seemingly unable to fine-tune the model with additional voice data.</p>
<p>Why is this the case, and how could it be fixed?</p>]]></description></item><item><title>Fast (5x) Inference with TorToiSe-TTS</title><link>https://152334H.github.io/blog/tortoise-tts-fast/</link><pubDate>Sun, 05 Feb 2023 20:28:55 +0800</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/tortoise-tts-fast/</guid><description>&lt;p>I made a fork of TorToiSe with much faster inference speed. Here are the summarised results:&lt;/p></description></item><item><title>Contrastive Search might-not-be What You Need</title><link>https://152334H.github.io/blog/anisotropy/</link><pubDate>Mon, 12 Dec 2022 19:08:08 +0800</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/anisotropy/</guid><description><![CDATA[<h4>TL;DR</h4>
<ul>
<li><u><strong>GPT-NeoX-20B appears to be anisotropic</strong></u> (Isotropy: 0.197)</li>
<li>Int8 quantisation appears to have ~no effect on isotropy</li>
<li>I am new to ML so the above could be false, feel free to poke at my findings <a href="https://github.com/152334H/Contrastive_Search_Is_What_You_Need/tree/main/isotropy_analysis" target="_blank" rel="noopener noreffer ">here</a></li>
</ul>]]></description></item><item><title>Why Language Models?</title><link>https://152334H.github.io/blog/why-lms/</link><pubDate>Sun, 27 Nov 2022 12:00:00 +0800</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/why-lms/</guid><description>A preface to the upcoming series on my attempts to use language models, locally</description></item><item><title>Recent ML Projects</title><link>https://152334H.github.io/blog/end-of-hiatus/</link><pubDate>Sun, 27 Nov 2022 00:00:00 +0800</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/end-of-hiatus/</guid><description><![CDATA[<p>2 months ago, I was halfway into publishing a series on my <a href="/disco-narrator" rel="">TTS project</a>. Today, the site for that project is defunct, and no new posts have been made about it.</p>
<p>What happened?</p>]]></description></item><item><title>Multiprocessing and &lt;code>random()&lt;/code></title><link>https://152334H.github.io/blog/multiprocessing-and-random/</link><pubDate>Sun, 02 Oct 2022 00:00:00 +0800</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/multiprocessing-and-random/</guid><description><![CDATA[<p>Let&rsquo;s say, for <a href="https://huggingface.co/blog/stable_diffusion" target="_blank" rel="noopener noreffer ">some odd reason</a>, you&rsquo;re hosting a Python service that:</p>
<ol>
<li>takes requests that run large computations based on a randomly generated number (a &ldquo;seed&rdquo;)</li>
<li>spreads work across multiple workers to handle many requests</li>
</ol>
<p>Then, it&rsquo;s likely you&rsquo;ll introduce a subtle randomness bug that leads to duplicate seeds appearing. Let me explain:</p>]]></description></item><item><title>Disco Narrator - Data Formatting</title><link>https://152334H.github.io/blog/dn-2/</link><pubDate>Sun, 25 Sep 2022 00:00:00 +0100</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/dn-2/</guid><description>&lt;p>With the raw data in tow, we can construct a proper TTS Dataset with the use of a few Python scripts.&lt;/p></description></item><item><title>Phonecoding</title><link>https://152334H.github.io/blog/funcoding-setup/</link><pubDate>Sun, 18 Sep 2022 00:00:00 +0100</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/funcoding-setup/</guid><description><![CDATA[<p>Back when 2019&rsquo;s <a href="https://adventofcode.com" target="_blank" rel="noopener noreffer ">Advent of Code</a> was going on, I started a habit of what I now call <code>phonecoding</code> &ndash; the act of programming using a run-of-the-mill Android smartphone.</p>]]></description></item><item><title>Disco Narrator - Data Scraping</title><link>https://152334H.github.io/blog/dn-1/</link><pubDate>Sun, 11 Sep 2022 00:00:00 +0100</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/dn-1/</guid><description><![CDATA[<p>To train an AI Text-To-Speech (TTS) model, we&rsquo;ll need to obtain a Labelled Dataset with two things:</p>
<ol>
<li>Clean audio files, containing only the voice we&rsquo;re cloning</li>
<li>The dialogue transcript (text) for each audio file</li>
</ol>]]></description></item></channel></rss>