<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>language models - Tag - 152334H</title><link>https://152334H.github.io/tags/language-models/</link><description>language models - Tag - 152334H</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 12 Dec 2022 19:08:08 +0800</lastBuildDate><atom:link href="https://152334H.github.io/tags/language-models/" rel="self" type="application/rss+xml"/><item><title>Contrastive Search might-not-be What You Need</title><link>https://152334H.github.io/blog/anisotropy/</link><pubDate>Mon, 12 Dec 2022 19:08:08 +0800</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/anisotropy/</guid><description><![CDATA[<h4>TL;DR</h4>
<ul>
<li><u><strong>GPT-NeoX-20B appears to be anisotropic</strong></u> (Isotropy: 0.197)</li>
<li>Int8 quantisation appears to have ~no effect on isotropy</li>
<li>I am new to ML so the above could be false, feel free to poke at my findings <a href="https://github.com/152334H/Contrastive_Search_Is_What_You_Need/tree/main/isotropy_analysis" target="_blank" rel="noopener noreffer ">here</a></li>
</ul>]]></description></item><item><title>An Informal Reminder</title><link>https://152334H.github.io/blog/an-informal-reminder/</link><pubDate>Fri, 02 Dec 2022 05:15:20 +0800</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/an-informal-reminder/</guid><description>&lt;figure>
&lt;/figure></description></item><item><title>Why Language Models?</title><link>https://152334H.github.io/blog/why-lms/</link><pubDate>Sun, 27 Nov 2022 12:00:00 +0800</pubDate><author>152334H</author><guid>https://152334H.github.io/blog/why-lms/</guid><description>A preface to the upcoming series on my attempts to use language models, locally</description></item></channel></rss>