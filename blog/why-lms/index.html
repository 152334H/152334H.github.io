<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Why Language Models? - 152334H</title><meta name=Description content="A preface to the upcoming series on my attempts to use language models, locally"><meta property="og:title" content="Why Language Models?"><meta property="og:description" content="A preface to the upcoming series on my attempts to use language models, locally"><meta property="og:type" content="article"><meta property="og:url" content="https://152334H.github.io/blog/why-lms/"><meta property="og:image" content="https://152334H.github.io/undefined.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-27T12:00:00+08:00"><meta property="article:modified_time" content="2022-11-27T16:44:18+08:00"><meta property="og:site_name" content="152334H"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://152334H.github.io/undefined.png"><meta name=twitter:title content="Why Language Models?"><meta name=twitter:description content="A preface to the upcoming series on my attempts to use language models, locally"><meta name=application-name content="My cool site"><meta name=apple-mobile-web-app-title content="My cool site"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://152334H.github.io/blog/why-lms/><link rel=prev href=https://152334H.github.io/blog/end-of-hiatus/><link rel=next href=https://152334H.github.io/blog/an-informal-reminder/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Why Language Models?","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/152334H.github.io\/blog\/why-lms\/"},"genre":"posts","keywords":"language models, personal, machine learning","wordcount":733,"url":"https:\/\/152334H.github.io\/blog\/why-lms\/","datePublished":"2022-11-27T12:00:00+08:00","dateModified":"2022-11-27T16:44:18+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"152334H"},"description":"A preface to the upcoming series on my attempts to use language models, locally"}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"dark"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"dark"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=152334H>Simple Thoughts</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>All Posts </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/categories/>Categories </a><a class=menu-item href=/about/><b>About </b></a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=Search... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=152334H>Simple Thoughts</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=Search... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/ title>All Posts</a><a class=menu-item href=/tags/ title>Tags</a><a class=menu-item href=/categories/ title>Categories</a><a class=menu-item href=/about/ title><b>About</b></a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Why Language Models?</h1><h2 class=single-subtitle>Part 0/X</h2><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://152334H.github.io/ title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>152334H</a></span>&nbsp;<span class=post-category>included in <a href=/categories/tech/><i class="far fa-folder fa-fw" aria-hidden=true></i>tech</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime="November 27, 2022">November 27, 2022</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;733 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;4 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept=true><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#models-need-less-vram-now>Models need less vram now</a></li><li><a href=#advances-in-sampling-strategies>Advances in sampling strategies</a></li><li><a href=#i-wanted-to-write-blogposts-again>I wanted to write blogposts again</a></li></ul></nav></div></div><div class=content id=content><p>Over the course of the last month or so, I&rsquo;ve been working on a <a href=https://github.com/152334H/gpt-j-editor target=_blank rel="noopener noreffer">webapp text editor</a> that uses <a href=https://huggingface.co/EleutherAI/gpt-j-6B target=_blank rel="noopener noreffer">GPT-J</a>, a language model, to perform autocomplete. If you don&rsquo;t know what that is, then <a href=https://xkcd.com/1053/ target=_blank rel="noopener noreffer">I hope you&rsquo;ll enjoy</a> some of the links in this blogpost.</p><p>But for the majority that <em>does</em> know what language models are, it&rsquo;s safe to say that I&rsquo;ve done nothing complex. Technologically, I made a <a href=https://create-react-app.dev/ target=_blank rel="noopener noreffer">React app</a> with a text editor derived from <a href=https://docs.slatejs.org/ target=_blank rel="noopener noreffer">Slate.js</a>, and connected that to a <a href=https://fastapi.tiangolo.com/ target=_blank rel="noopener noreffer">FastAPI backend</a> which throws requests to huggingface&rsquo;s <a href=https://huggingface.co/docs/transformers/index target=_blank rel="noopener noreffer"><code>transformers</code></a>.</p><p>None of this is revolutionary. There are many solutions online that do way better. EleutherAI hosts their own free <a href=https://20b.eleuther.ai/ target=_blank rel="noopener noreffer">demo page</a> that runs a lot more elegantly than my webapp. OpenAI&rsquo;s <a href=https://beta.openai.com/playground/ target=_blank rel="noopener noreffer">GPT3 models</a> are a lot better than anything open source can provide. And companies like <a href=https://novelai.net/ target=_blank rel="noopener noreffer">NovelAI</a> corner the <em>submarket</em> of people who want to do more specific tasks like writing certain kinds of fiction novels.</p><p>So, why am I even working on any of this?</p><hr><h2 id=models-need-less-vram-now>Models need less vram now</h2><p>Back in August, someone published a paper titled <a href=https://arxiv.org/abs/2208.07339 target=_blank rel="noopener noreffer">LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</a>. I recommend reading the <a href=https://huggingface.co/blog/hf-bitsandbytes-integration target=_blank rel="noopener noreffer">huggingface article</a> on it if you&rsquo;re interested, but in short,</p><blockquote><p>With our method, a 175B parameter 16/32-bit checkpoint can be loaded, converted to Int8, and used immediately without performance degradation.</p></blockquote><p>Now, 175B parameters is still pretty big. With Int8, it&rsquo;d be <em>175 gigabytes of memory</em>, which is still well in the category of &ldquo;not for personal use&rdquo;.</p><p>But the improvements apply for <em>any</em> language model reliant on the <a href=https://medium.com/@adityathiruvengadam/transformer-architecture-attention-is-all-you-need-aeccd9f50d09 target=_blank rel="noopener noreffer">transformer architecture</a>. And there are many great models that are now accessible to larger sections of the general population because of this.</p><table><thead><tr><th>Model</th><th>3050 (4GB)</th><th>2080 TI (11GB)</th><th>Tesla T4 (16GB)</th><th>3090 (24GB)</th></tr></thead><tbody><tr><td>Codegen-2B</td><td>✅</td><td>⬛</td><td>⬛</td><td>⬛</td></tr><tr><td>GPT-J-6B</td><td>❌</td><td>✅</td><td>⬛</td><td>⬛</td></tr><tr><td>CodeGeeX-13B</td><td>❌</td><td>❌</td><td>✅</td><td>✅</td></tr><tr><td>GPT-NeoX-20B</td><td>❌</td><td>❌</td><td>❌</td><td>✅</td></tr></tbody></table><p align=center>✅ - int8 improvement | ⬛ - no change | ❌ - int8 insufficient</p><p>If you have an <a href=https://www.techpowerup.com/gpu-specs/geforce-rtx-3090.c3622 target=_blank rel="noopener noreffer">RTX 3090</a>, you can run <a href=https://nn.labml.ai/neox/utils/llm_int8.html target=_blank rel="noopener noreffer">GPT-NeoX-20B</a> or <a href=https://github.com/THUDM/CodeGeeX target=_blank rel="noopener noreffer">CodeGeeX-13B</a>. If you have a 2080, you can run GPT-J-6B or <a href=https://huggingface.co/facebook/incoder-6B target=_blank rel="noopener noreffer">Incoder-6B</a>. And if you have enough memory to run Stable Diffusion, you can run <a href=https://github.com/salesforce/CodeGen target=_blank rel="noopener noreffer">Codegen-2B</a>.</p><p>That last example is particularly motivating, because of the next section.</p><h2 id=advances-in-sampling-strategies>Advances in sampling strategies</h2><p>Earlier this month, huggingface implemented <a href=https://huggingface.co/blog/introducing-csearch target=_blank rel="noopener noreffer">Contrastive Search</a> into their <code>transformers</code> library. While I&rsquo;m not at all qualified to describe what it does (and whether it is &rsquo;novel&rsquo; or &lsquo;obvious&rsquo;), I find their <a href=https://arxiv.org/pdf/2210.14140 target=_blank rel="noopener noreffer">results</a> rather encouraging.</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://user-images.githubusercontent.com/54623771/201234331-7ca646f7-a3f4-448c-94e2-707a1eea235c.jpg data-srcset="https://user-images.githubusercontent.com/54623771/201234331-7ca646f7-a3f4-448c-94e2-707a1eea235c.jpg, https://user-images.githubusercontent.com/54623771/201234331-7ca646f7-a3f4-448c-94e2-707a1eea235c.jpg 1.5x, https://user-images.githubusercontent.com/54623771/201234331-7ca646f7-a3f4-448c-94e2-707a1eea235c.jpg 2x" data-sizes=auto alt=https://user-images.githubusercontent.com/54623771/201234331-7ca646f7-a3f4-448c-94e2-707a1eea235c.jpg title=https://user-images.githubusercontent.com/54623771/201234331-7ca646f7-a3f4-448c-94e2-707a1eea235c.jpg></p><p>A 3% jump might not sound like much, but <strong>it puts CodeGen-2B at the same level as <a href=https://github.com/VHellendoorn/Code-LMs#results---humaneval target=_blank rel="noopener noreffer">Codex-2.5B</a></strong>. This puts open source replacements for Copilot (like <a href=https://github.com/moyix/fauxpilot target=_blank rel="noopener noreffer">fauxpilot</a>) at the same level of code completion competency.</p><p>Contrastive search also does a lot better at long-form writing than other sampling strategies, which is great because:</p><h2 id=i-wanted-to-write-blogposts-again>I wanted to write blogposts again</h2><p>I&rsquo;m not very good at writing. While I don&rsquo;t think the things I publish are <em>terrible</em>, I often feel that I take way too long to get from &lsquo;idea&rsquo; to &lsquo;written essay&rsquo;. And I&rsquo;m sure that&rsquo;s not a unique problem, but it&rsquo;s the kind of problem that a lot of people seem to shrug at and say,</p><blockquote><p>Guess I have to try harder.</p></blockquote><p>Or,</p><blockquote><p>Guess I can&rsquo;t do much of that</p></blockquote><p>I don&rsquo;t like either of these options. The third option, &ldquo;Make an computer do it for you,&rdquo; is what language models are. But I also don&rsquo;t really like sending my drafted blogposts to a remote SaaS, so I wanted a solution that could run locally on my own hardware.</p><p>And that was surprisingly difficult to find online. I did some googling, asked a few communities, double checked a laundry list of github tags to make sure I didn&rsquo;t miss anything, and somehow I <em>just found nothing</em>. I&rsquo;m still 90% certain someone has already done, &ldquo;Open source webapp editor that uses GPT-J,&rdquo; but for the life of me, I couldn&rsquo;t find it. The searches I got were <a href=https://github.com/nhaouari/obsidian-textgenerator-plugin target=_blank rel="noopener noreffer">polluted</a> with <a href=https://github.com/jameshiew/nvim-magic target=_blank rel="noopener noreffer">solutions</a> that, while open source, were only designed to send requests to OpenAI&rsquo;s GPT3 API. Great for most people; not what I&rsquo;m looking for.</p><p>So, I got to work on a simple tool that would help me to run GPT-J locally, thinking it would take me less than a weekend to finish.</p><hr><p>The next few blogposts in this series will cover how I ended up spending a month doing just that.</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on November 27, 2022&nbsp;<a class=git-hash href=https://github.com/152334H/blog/commit/a430fce7e399aee111443599f5ccb1a94a2cfc4f target=_blank title="commit by 152334H(54623771+152334H@users.noreply.github.com) a430fce7e399aee111443599f5ccb1a94a2cfc4f: hi">
<i class="fas fa-hashtag fa-fw" aria-hidden=true></i>a430fce</a></span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://152334H.github.io/blog/why-lms/ data-title="Why Language Models?" data-hashtags="language models,personal,machine learning"><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://152334H.github.io/blog/why-lms/ data-hashtag="language models"><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Linkedin" data-sharer=linkedin data-url=https://152334H.github.io/blog/why-lms/><i class="fab fa-linkedin fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://152334H.github.io/blog/why-lms/ data-title="Why Language Models?"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Reddit" data-sharer=reddit data-url=https://152334H.github.io/blog/why-lms/><i class="fab fa-reddit fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://152334H.github.io/blog/why-lms/ data-title="Why Language Models?"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://152334H.github.io/blog/why-lms/ data-title="Why Language Models?"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/language-models/>language models</a>,&nbsp;<a href=/tags/personal/>personal</a>,&nbsp;<a href=/tags/machine-learning/>machine learning</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/blog/end-of-hiatus/ class=prev rel=prev title="Recent ML Projects"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Recent ML Projects</a>
<a href=/blog/an-informal-reminder/ class=next rel=next title="An Informal Reminder">An Informal Reminder<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div><div id=comments><div id=giscus class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://giscus.app>Giscus</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2022 - 2023</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://152334H.github.io/ target=_blank>152334H</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/twemoji@14.0.2/dist/twemoji.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{giscus:{category:"Announcements",categoryId:"DIC_kwDOH03r284CQ2Tu",darkTheme:"dark_dimmed",emitMetadata:"0",inputPosition:"bottom",lang:"en",lazyLoading:!1,lightTheme:"light",mapping:"pathname",reactionsEnabled:"1",repo:"152334H/152334h.github.io",repoId:"R_kgDOH03r2w"}},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"},twemoji:!0}</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-W0STJ4D3N3",{anonymize_ip:!0})</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=G-W0STJ4D3N3" async></script></body></html>